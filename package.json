{
  "name": "claude-code-ollama-proxy",
  "version": "0.1.0",
  "description": "A CLI proxy that lets Claude Code (and any Anthropic-API-compatible client) use locally-running models via Ollama",
  "keywords": [
    "claude",
    "ollama",
    "proxy",
    "anthropic",
    "llm",
    "ai",
    "claude-code"
  ],
  "homepage": "https://github.com/Herz-Cloud-AI-GmbH/claude-code-ollama-proxy#readme",
  "bugs": {
    "url": "https://github.com/Herz-Cloud-AI-GmbH/claude-code-ollama-proxy/issues"
  },
  "license": "MIT",
  "author": "Herz Cloud & AI GmbH",
  "type": "module",
  "main": "./dist/server.js",
  "bin": {
    "claude-code-ollama-proxy": "./dist/cli.js"
  },
  "files": [
    "dist"
  ],
  "scripts": {
    "build": "tsup",
    "dev": "tsx src/cli.ts",
    "start": "node dist/cli.js",
    "test": "vitest run",
    "test:watch": "vitest",
    "test:coverage": "vitest run --coverage",
    "typecheck": "tsc --noEmit"
  },
  "dependencies": {
    "commander": "^12.1.0",
    "cors": "^2.8.5",
    "express": "^4.21.2"
  },
  "devDependencies": {
    "@types/cors": "^2.8.17",
    "@types/express": "^5.0.0",
    "@types/node": "^22.10.5",
    "tsup": "^8.3.5",
    "tsx": "^4.19.2",
    "typescript": "^5.7.3",
    "vitest": "^4.0.18"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}
